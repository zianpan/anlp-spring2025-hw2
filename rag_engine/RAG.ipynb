{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/anlp-hw2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# RAG_System.ipynb\n",
    "\n",
    "# ============================\n",
    "# 1. Install Required Packages\n",
    "# ============================\n",
    "# You might already have some or all of these. If so, you can skip or comment them out.\n",
    "# %pip install langchain transformers chromadb sentence-transformers accelerate bitsandbytes  # etc.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "import shutil\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2. Configuration\n",
    "# ============================\n",
    "# Path to data folder\n",
    "DATA_PATH = \"../data\" \n",
    "\n",
    "# Choose an embedding model.\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Choose a local LLM model.\n",
    "LLM_MODEL_ID = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "retriever_top_k  = 4\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify files in the folder\n",
    "\n",
    "files_txt_path = []\n",
    "files_csv_path = []\n",
    "\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            files_txt_path.append(os.path.join(root, file))\n",
    "        elif file.endswith('.csv'):\n",
    "            files_csv_path.append(os.path.join(root, file))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1231 raw documents from 1 files.\n",
      "Total 2827 final chunks prepared for vector storage.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 2. Load Files with Different Strategies\n",
    "# ============================\n",
    "all_documents = []\n",
    "\n",
    "# Load all files in the directory\n",
    "for file_path in files_txt_path:\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    doc = loader.load()  # Load entire file as one document\n",
    "    all_documents.append(Document(page_content=doc[0].page_content, metadata={\"source\": file_path}))\n",
    "\n",
    "for file_path in files_csv_path:\n",
    "    df = pd.read_csv(file_path)\n",
    "    filename = os.path.basename(file_path)\n",
    "    for index, row in df.iterrows():\n",
    "        row_text = f\"{filename} | \" + \" | \".join(f\"{col}: {row[col]}\" for col in df.columns)\n",
    "        metadata = {\"source\": filename, \"row_id\": index}\n",
    "        all_documents.append(Document(page_content=row_text, metadata=metadata))\n",
    "\n",
    "\n",
    "## OPTIOANL function for processing files row by row\n",
    "#     # ✅ Load row by row (structured data)\n",
    "#     if filename in ROW_BY_ROW_FILES:\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#             for row_id, line in enumerate(file):\n",
    "#                 line = line.strip()\n",
    "#                 if line:  # Ignore empty lines\n",
    "#                     all_documents.append(Document(page_content=line, metadata={\"source\": filename, \"row_id\": row_id}))\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} raw documents from {len(os.listdir(DATA_PATH))} files.\")\n",
    "\n",
    "# ============================\n",
    "# 3. Split Longer Documents for Better Retrieval\n",
    "# ============================\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "split_documents = []\n",
    "for doc in all_documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)  # Split if needed\n",
    "    for chunk in chunks:\n",
    "        split_documents.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "print(f\"Total {len(split_documents)} final chunks prepared for vector storage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/yrdfvq7156ggy1rjy5rj56gh0000gn/T/ipykernel_31743/825499093.py:24: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded successfully.\n",
      "Vector store recreated and persisted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/yrdfvq7156ggy1rjy5rj56gh0000gn/T/ipykernel_31743/825499093.py:44: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 4. Create Embeddings\n",
    "# ============================\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "print(\"Embeddings loaded successfully.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Manage Vector Store\n",
    "# ============================\n",
    "persist_directory = \"chroma_db\"\n",
    "\n",
    "# Check if the vector store exists and delete it if necessary\n",
    "if os.path.exists(persist_directory):\n",
    "    print(\"Vector store exists. Deleting existing database...\")\n",
    "    shutil.rmtree(persist_directory)  # Deletes the existing database folder\n",
    "\n",
    "# Recreate the vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(\"Vector store recreated and persisted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Falcon 7B Instruct model; this may take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.82s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 6. Set Up the LLM (Falcon 7B Instruct)\n",
    "# ============================\n",
    "# Load the tokenizer and model\n",
    "print(\"Loading Falcon 7B Instruct model; this may take some time...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"mps\",           # automatically place model layers on available GPU\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/var/folders/gz/yrdfvq7156ggy1rjy5rj56gh0000gn/T/ipykernel_31743/2853950461.py:13: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipeline_llm)\n"
     ]
    }
   ],
   "source": [
    "# Create a text-generation pipeline\n",
    "pipeline_llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.2,       # Lower temperature for more factual answers\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,\n",
    ")\n",
    "\n",
    "# Wrap the pipeline in a LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=pipeline_llm)\n",
    "\n",
    "\n",
    "# Customized Prompt\n",
    "\n",
    "QA_Prompt = \"\"\"\n",
    "You are an expert assistant answering factual questions about Pittsburgh or Carnegie Mellon University (CMU). \n",
    "Use the retrieved information to give a detailed and helpful answer. If the provided context does not contain the answer, leverage your pretraining knowledge to provide the correct answer. \n",
    "If you truly do not know, just say \"I don't know.\"\n",
    "\n",
    "Important Instructions:\n",
    "- Answer concisely without repeating the question.\n",
    "- Use the provided context if relevant; otherwise, rely on your pretraining knowledge.\n",
    "- Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
    "\n",
    "Examples:\n",
    "Question: Who is Pittsburgh named after? \n",
    "Answer: William Pitt\n",
    "Question: What famous machine learning venue had its first conference in Pittsburgh in 1980? \n",
    "Answer: ICML\n",
    "Question: What musical artist is performing at PPG Arena on October 13? \n",
    "Answer: Billie Eilish\n",
    "\n",
    "- Please answer the following question based on the provided context, the information in the example above might not be relevant to the current context.\n",
    "\n",
    "Context: \\n\\n {context} \\n\\n\n",
    "Question: {question} \\n\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(template=QA_Prompt, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 7. Create the RetrievalQA Chain\n",
    "# ============================\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": retriever_top_k})\n",
    "\n",
    "\n",
    "def ask_question(query: str):\n",
    "    \"\"\"\n",
    "    Run a query through the RAG pipeline and return the generated answer along with the source documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user’s question.\n",
    "\n",
    "    Returns:\n",
    "        answer (str): The generated answer.\n",
    "        sources (list): List of retrieved documents used to generate the answer.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # Extract text from retrieved documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # Format the input using the QA_Prompt\n",
    "    formatted_prompt = QA_Prompt.format(context=context, question=query)\n",
    "\n",
    "    # Generate response using the LLM\n",
    "    result = llm(formatted_prompt)  # Pass the fully formatted input\n",
    "\n",
    "    # Extract answer and sources\n",
    "    answer = result.strip()  # Ensure clean output\n",
    "    return answer, retrieved_docs  # Return both answer and retrieved documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/yrdfvq7156ggy1rjy5rj56gh0000gn/T/ipykernel_31743/2853950461.py:86: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n",
      "/var/folders/gz/yrdfvq7156ggy1rjy5rj56gh0000gn/T/ipykernel_31743/2853950461.py:95: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm(formatted_prompt)  # Pass the fully formatted input\n",
      "/opt/miniconda3/envs/anlp-hw2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/anlp-hw2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When is The Way Of Tea: Ceremony And Recital taking place?\n",
      "Answer: You are an expert assistant answering factual questions about Pittsburgh or Carnegie Mellon University (CMU). \n",
      "Use the retrieved information to give a detailed and helpful answer. If the provided context does not contain the answer, leverage your pretraining knowledge to provide the correct answer. \n",
      "If you truly do not know, just say \"I don't know.\"\n",
      "\n",
      "Important Instructions:\n",
      "- Answer concisely without repeating the question.\n",
      "- Use the provided context if relevant; otherwise, rely on your pretraining knowledge.\n",
      "- Do **not** use complete sentences. Provide only the word, name, date, or phrase that directly answers the question. For example, given the question \"When was Carnegie Mellon University founded?\", you should only answer \"1900\".\n",
      "\n",
      "Examples:\n",
      "Question: Who is Pittsburgh named after? \n",
      "Answer: William Pitt\n",
      "Question: What famous machine learning venue had its first conference in Pittsburgh in 1980? \n",
      "Answer: ICML\n",
      "Question: What musical artist is performing at PPG Arena on October 13? \n",
      "Answer: Billie Eilish\n",
      "\n",
      "- Please answer the following question based on the provided context, the information in the example above might not be relevant to the current context.\n",
      "\n",
      "Context: \n",
      "\n",
      " ---\n",
      "Event #2\n",
      "Raw:\n",
      "The Way Of Tea: Ceremony And Recital\n",
      "Monday, March 10, 2025\n",
      "06:00 PM - 08:30 PM\n",
      "The Art Room, 2010 Smallman St, Pittsburgh PA 15222\n",
      "View Details\n",
      "\n",
      "Details:\n",
      "Return to Events Calendar\n",
      "The Way of Tea: Recital and Ceremony\n",
      "The Art Room, 2010 Smallman St, Pittsburgh PA 15222\n",
      "March 10, 2025\n",
      "6:00 PM-8:30 PM\n",
      "  Ceremony\n",
      "The tea ceremony, or Chado (The Way of Tea), is a traditional Japanese art involving the ritualistic preparation of tea. Influenced by the philosophy of Zen Buddhism, the core teaching of chado is to attain a spiritual state of selflessness and peacefulness through making and sharing tea. Join us to learn the history and philosophy of Japanese tea ceremony while tasting Japanese tea and sweets.\n",
      "\n",
      "Maestro's Wine Dinner\n",
      "Wed, Apr 23, 2025\n",
      "SEE EVENT DESCRIPTION\n",
      "Pittsburgh Symphony Orchestra\n",
      "\n",
      "Beethoven and Brahms\n",
      "Fri, Apr 25 - Sun, Apr 27, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Classical Live Music\n",
      "\n",
      "Music of Star Wars\n",
      "Sat, May 3, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Live Music Concert\n",
      "\n",
      "Clouds in my Coffee: Music of Joni Mitchell, Carole King & Carly Simon\n",
      "Fri, May 9 - Sun, May 11, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Live Music Concert\n",
      "\n",
      "Bronfman Plays Beethoven\n",
      "Fri, May 16 - Sun, May 18, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Classical Live Music\n",
      "\n",
      "Brahms’ Fourth Symphony\n",
      "Fri, May 30 - Sun, Jun 1, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Classical Live Music\n",
      "\n",
      "Yo-Yo Ma\n",
      "Wed, Jun 4, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Classical Live Music\n",
      "\n",
      "Beethoven and Mahler\n",
      "Fri, Jun 6 - Sun, Jun 8, 2025\n",
      "HEINZ HALL\n",
      "Pittsburgh Symphony Orchestra\n",
      "Classical Live Music\n",
      "\n",
      "'https://www.pittsburghsymphony.org/production/98994/grimaud-plays-gershwin',\n",
      " 'https://www.pittsburghsymphony.org/production/99000/himari-plays-bruch',\n",
      " 'https://www.pittsburghsymphony.org/production/93245/total-eclipse-of-the-chart-music-of-the-80s',\n",
      " 'https://www.pittsburghsymphony.org/production/99003/shostakovichs-fifth',\n",
      " 'https://www.pittsburghsymphony.org/production/98705/discovery-and-drinks-music-and-cinema-2',\n",
      " 'https://www.pittsburghsymphony.org/production/99035/the-rite-of-spring',\n",
      " 'https://www.pittsburghsymphony.org/production/92958/lisiecki-performs-mozart',\n",
      " 'https://www.pittsburghsymphony.org/production/93521/pso-disrupt-hope-and-resistance',\n",
      " 'https://www.pittsburghsymphony.org/production/92960/beethovens-pastoral',\n",
      " 'https://www.pittsburghsymphony.org/production/100209/disrupt-2',\n",
      " 'https://www.pittsburghsymphony.org/production/99013/brahms-third',\n",
      " 'https://www.pittsburghsymphony.org/production/99010/spacek-plays-dvorak',\n",
      "\n",
      "Details:\n",
      "Return to Events Calendar\n",
      "Maecenas XL\n",
      "Saturday, May 17, 2025\n",
      "Monterey Bay Fish Grotto (1411 Grandview Avenue)\n",
      "\n",
      "The Ruby Anniversary of our signature black-tie event with dinner, dancing, and awards to celebrate a successful season.\n",
      "\n",
      "---\n",
      "Event #27\n",
      "Raw:\n",
      "Bravo Academy Session 1\n",
      "Monday, July 7, 2025 to Friday, July 11, 2025\n",
      "09:00 AM - 04:00 PM\n",
      "Bitz Opera Factory\n",
      "View Details\n",
      "\n",
      "Details:\n",
      "Return to Events Calendar\n",
      "Bravo Academy\n",
      "Session 1\n",
      "Bitz Opera Factory\n",
      "July 7-11 \n",
      "9am-4pm\n",
      "    Is your child interested in the magic that goes on backstage of a performance?\n",
      "\n",
      "Then Bravo Academy is for YOU!\n",
      "\n",
      "If you are an aspiring young singer, have a talent for creating the magic of the backstage world, or are a budding opera aficionado, this is the program for you! Focusing on musical theater, opera, and art song favorites, Bravo Academy ensures that all participants will have a chance to shine in the limelight. \n",
      "\n",
      "\n",
      "Question: When is The Way Of Tea: Ceremony And Recital taking place? \n",
      "\n",
      "\n",
      "Answer:\n",
      "The Way Of Tea: Ceremony And Recital is taking place on Monday, March 10, 2025.\n",
      "\n",
      "Sources used:\n",
      "[Source 1] ../data/zianp/pittsburgh_opera/pittsburgh_opera_events.txt\n",
      "[Source 2] ../data/zianp/pittsburgh_symphony/pittsburgh_symphony.txt\n",
      "[Source 3] ../data/zianp/picklesburgh/remain_websites.txt\n",
      "[Source 4] ../data/zianp/pittsburgh_opera/pittsburgh_opera_events.txt\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "user_question = \"What time will Kimberly Akimbo take place?\"\n",
    "user_question = \"Which events are taking place at the Carnegie of Homestead Music Hall?\"\n",
    "user_question = \"When is The Way Of Tea: Ceremony And Recital taking place?\"\n",
    "\n",
    "answer, sources = ask_question(user_question)\n",
    "\n",
    "# print(\"Question:\", user_question)\n",
    "print(answer)\n",
    "print(\"\\nSources used:\")\n",
    "for i, doc in enumerate(sources):\n",
    "    print(f\"[Source {i+1}] {doc.metadata.get('source', 'Unknown source')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
